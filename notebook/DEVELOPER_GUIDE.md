# üîß Guide D√©veloppeur DontREADME

> **Documentation technique compl√®te pour comprendre, modifier et √©tendre DontREADME**

Ce guide explique en d√©tail l'architecture, les composants, et le fonctionnement interne de DontREADME. Id√©al pour les d√©veloppeurs souhaitant comprendre, modifier ou √©tendre le syst√®me.

## üìÅ Architecture du Projet

### Vue d'Ensemble
```
DontREADME/
‚îú‚îÄ‚îÄ üì± app/                    # Application principale
‚îú‚îÄ‚îÄ üîß utils/                  # Utilitaires avanc√©s
‚îú‚îÄ‚îÄ üîÑ workflows/              # Orchestration Prefect
‚îú‚îÄ‚îÄ üìù scripts/                # Scripts d'automatisation
‚îú‚îÄ‚îÄ üìä data/                   # Donn√©es et stockage
‚îú‚îÄ‚îÄ üß™ tests/                  # Tests (structure pr√©par√©e)
‚îú‚îÄ‚îÄ üìã logs/                   # Logs syst√®me
‚îî‚îÄ‚îÄ üìö docs/                   # Documentation
```

## üèóÔ∏è Structure D√©taill√©e

### üì± **Dossier `app/` - Application Principale**

#### `app/main.py` - Point d'Entr√©e Principal
**R√¥le** : Interface Gradio unifi√©e avec orchestration int√©gr√©e
```python
class EnhancedDocumentChatBot:
    """Application principale am√©lior√©e"""
    
    def __init__(self):
        self.chat_engine = EnhancedChatEngine()         # Moteur de conversation
        self.global_monitor = PerformanceMonitor()      # Monitoring global
        self.current_document = None                     # Document actuel
        self.document_processed = False                  # √âtat traitement
        self.system_status = {}                          # Statut syst√®me
```

**Fonctions cl√©s** :
- `process_document_enhanced()` : Traitement document avec monitoring
- `chat_enhanced()` : Conversation avec m√©tadonn√©es enrichies
- `get_detailed_status()` : Statut syst√®me d√©taill√©
- `export_session_data()` : Export complet de session

**Interface Gradio** :
- **Onglet Configuration** : Upload et param√©trage
- **Onglet Chat** : Conversation intelligente  
- **Onglet Monitoring** : M√©triques et export
- **Onglet Orchestration** : Workflows Prefect

#### `app/config.py` - Configuration Centrale
**R√¥le** : Centralisation de toutes les configurations syst√®me
```python
class Config:
    # Param√®tres de base
    DEFAULT_CHUNK_SIZE = 1000
    DEFAULT_K_DOCUMENTS = 3
    MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB
    
    # Chemins
    CHROMADB_PATH = "./data/vectorstore"
    UPLOAD_PATH = "./data/uploads"
    
    # Mod√®les IA
    MISTRAL_MODEL = "mistral-tiny"
    EMBEDDING_MODEL = "all-MiniLM-L6-v2"
    
    # S√©curit√©
    ALLOWED_EXTENSIONS = ['.pdf', '.docx', '.txt']
    MAX_TOKENS = 4000
```

#### `app/components/` - Composants Modulaires

##### `file_processor.py` - Traitement de Fichiers
**R√¥le** : Extraction de texte depuis diff√©rents formats
```python
class FileProcessor:
    @staticmethod
    def process_uploaded_file(file_path):
        """Traite un fichier upload√© selon son type"""
        # D√©tection automatique du type MIME
        # Extraction sp√©cialis√©e par format
        # Nettoyage et validation du texte
        
    @staticmethod  
    def extract_text_from_pdf(file_path):
        """Extraction PDF avec PyPDF2"""
        
    @staticmethod
    def extract_text_from_docx(file_path):
        """Extraction DOCX avec python-docx"""
```

##### `chat_engine.py` - Moteur de Conversation IA
**R√¥le** : Orchestration de la conversation avec Mistral AI
```python
class EnhancedChatEngine:
    def __init__(self):
        self.llm = None                                 # LLM Mistral
        self.vectorstore_manager = EnhancedVectorStoreManager()
        self.memory = ConversationMemory()              # Historique
        self.prompt_manager = PromptTemplateManager()   # Templates
        self.performance_monitor = PerformanceMonitor() # M√©triques
        
    def setup_llm(self, api_key, model="mistral-tiny"):
        """Configuration du LLM avec validation"""
        
    def process_document_smart(self, text, filename, chunk_size, template_type):
        """Traitement intelligent avec templates adaptatifs"""
        
    def chat_with_sources(self, question):
        """Conversation avec sources enrichies"""
```

##### `vectorstore.py` - Gestion Base Vectorielle
**R√¥le** : Gestion de ChromaDB et embeddings
```python
class EnhancedVectorStoreManager:
    def __init__(self):
        self.embeddings = None                          # HuggingFace embeddings
        self.vectorstore = None                         # ChromaDB
        self.text_splitter = SmartTextSplitter()       # D√©coupage intelligent
        self.performance_monitor = PerformanceMonitor()
        
    def initialize_vectorstore(self):
        """Initialisation ChromaDB avec configuration optimis√©e"""
        
    def add_documents_enhanced(self, text, filename, chunk_size, chunk_overlap):
        """Ajout de documents avec m√©tadonn√©es enrichies"""
        
    def similarity_search_with_details(self, query, k=3):
        """Recherche avec m√©tadonn√©es d√©taill√©es"""
```

##### `memory.py` - Gestion de la M√©moire
**R√¥le** : Historique et contexte conversationnel
```python
class ConversationMemory:
    def __init__(self, max_history=50):
        self.conversation_history = []
        self.max_history = max_history
        self.performance_history = []
        
    def add_exchange(self, question, answer, metadata):
        """Ajouter un √©change avec m√©tadonn√©es"""
        
    def get_relevant_context(self, current_question, max_context=3):
        """R√©cup√©rer le contexte pertinent"""
        
    def export_history(self):
        """Export complet de l'historique"""
```

##### `orchestration_manager.py` - Gestionnaire Prefect
**R√¥le** : Interface avec l'API Prefect pour orchestration
```python
class OrchestrationManager:
    def __init__(self):
        self.prefect_available = PREFECT_AVAILABLE
        self.api_url = "http://localhost:4200/api"
        self.status_cache = {}
        
    async def get_prefect_status(self):
        """R√©cup√©rer le statut g√©n√©ral de Prefect"""
        
    async def trigger_workflow(self, workflow_name, parameters):
        """D√©clencher un workflow Prefect"""
        
    async def get_workflow_status(self, run_id):
        """R√©cup√©rer le statut d'un workflow sp√©cifique"""
```

##### `prefect_bridge.py` - Pont Prefect
**R√¥le** : Ex√©cution directe de workflows sans serveur
```python
class PrefectBridge:
    def __init__(self):
        self.workflows_available = WORKFLOWS_AVAILABLE
        
    async def process_documents_batch(self, documents_folder, api_key):
        """Traiter des documents en lot via Prefect"""
        
    async def check_system_health(self, alert_threshold=70):
        """V√©rifier la sant√© du syst√®me via Prefect"""
        
    def run_sync(self, coro):
        """Ex√©cuter une coroutine de mani√®re synchrone pour Gradio"""
```

#### `orchestration_interface.py` - Interface Orchestration
**R√¥le** : Interface Gradio pour gestion des workflows
```python
class OrchestrationInterface:
    def __init__(self):
        self.manager = orchestration_manager
        self.current_runs = {}
        
    def refresh_status(self):
        """Actualiser le statut de Prefect"""
        
    def trigger_workflow_action(self, workflow_type, **kwargs):
        """D√©clencher une action de workflow"""
        
    def create_orchestration_tab(self):
        """Cr√©er l'onglet d'orchestration Prefect"""
```

### üîß **Dossier `utils/` - Utilitaires Avanc√©s**

#### `validators.py` - Validation et S√©curit√©
**R√¥le** : Validation compl√®te des entr√©es utilisateur
```python
class FileValidator:
    @staticmethod
    def validate_file(file_obj):
        """Validation compl√®te d'un fichier"""
        # V√©rification taille, type MIME, contenu
        # D√©tection de malware potentiel
        # Validation encodage
        
    @staticmethod
    def check_file_safety(file_path):
        """V√©rifications de s√©curit√© avanc√©es"""

class InputValidator:
    @staticmethod
    def validate_api_key(api_key, provider='mistral'):
        """Validation format cl√© API"""
        
    @staticmethod
    def sanitize_user_input(user_input):
        """Nettoyage et s√©curisation input utilisateur"""
        
    @staticmethod
    def validate_question(question):
        """Validation d'une question utilisateur"""
```

#### `performance.py` - Monitoring de Performance
**R√¥le** : Surveillance et m√©triques compl√®tes
```python
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {}
        self.start_times = {}
        self.system_stats = {}
        
    def measure_performance(self, operation_name):
        """D√©corateur pour mesurer les performances"""
        
    def track_system_resources(self):
        """Surveillance des ressources syst√®me"""
        
    def get_performance_summary(self):
        """R√©sum√© complet des performances"""
        
    def export_metrics(self, format='json'):
        """Export des m√©triques"""
```

#### `text_splitter.py` - D√©coupage Intelligent
**R√¥le** : D√©coupage adaptatif selon le type de document
```python
class SmartTextSplitter:
    def __init__(self):
        self.document_patterns = {
            'academic': r'\n\d+\.\s+|\n[A-Z][A-Z\s]+\n',
            'legal': r'\n(?:Art\.|Article|Section)\s+\d+',
            'technical': r'\n\d+\.\d+\s+|\n#+\s+',
            'general': r'\n\n+'
        }
        
    def detect_document_type(self, text):
        """D√©tection automatique du type de document"""
        
    def split_text_smart(self, text, chunk_size, chunk_overlap, doc_type):
        """D√©coupage intelligent avec pr√©servation de structure"""
        
    def extract_keywords(self, text, max_keywords=10):
        """Extraction de mots-cl√©s contextuels"""
```

#### `prompt_templates.py` - Templates de Prompts
**R√¥le** : Prompts optimis√©s par type de document
```python
class PromptTemplateManager:
    def __init__(self):
        self.templates = {
            'general': "...",
            'academic': "...", 
            'technical': "...",
            'legal': "...",
            'summary': "...",
            'extraction': "..."
        }
        
    def get_template(self, template_type):
        """R√©cup√©rer un template selon le type"""
        
    def auto_select_template(self, document_type, question_type):
        """S√©lection automatique du meilleur template"""
        
    def customize_template(self, base_template, customizations):
        """Personnalisation de template"""
```

### üîÑ **Dossier `workflows/` - Orchestration Prefect**

#### `tasks.py` - T√¢ches R√©utilisables
**R√¥le** : Biblioth√®que de t√¢ches Prefect atomiques
```python
@task(name="process_single_document", retries=2, tags=["document", "processing"])
def process_single_document(file_path, api_key, chunk_size=None, template_type="auto"):
    """Traiter un document unique via Prefect"""
    
@task(name="test_document_query", tags=["testing", "query"])
def test_document_query(question, api_key, expected_keywords=None):
    """Tester une requ√™te sur un document trait√©"""
    
@task(name="cleanup_old_data", tags=["maintenance", "cleanup"])
def cleanup_old_data(max_age_days=7, directories=None):
    """Nettoyer les fichiers anciens"""
    
@task(name="check_system_health", tags=["monitoring", "health"])
def check_system_health():
    """Effectuer une v√©rification de sant√© syst√®me"""
    
@task(name="generate_performance_report", tags=["monitoring", "report"])
def generate_performance_report(include_system_metrics=True):
    """G√©n√©rer un rapport de performance complet"""
```

#### `batch_processing.py` - Traitement par Lots
**R√¥le** : Workflows de traitement massif de documents
```python
@flow(name="batch_document_processing", task_runner=ConcurrentTaskRunner())
async def batch_document_flow(documents_folder, api_key, file_extensions=None):
    """Traiter plusieurs documents en parall√®le"""
    
@flow(name="process_folder_documents")
async def process_folder_documents(input_folder, api_key, output_report=None):
    """Workflow complet pour traiter un dossier avec surveillance"""
    
@flow(name="nightly_batch_processing")
async def nightly_batch_processing(watch_folder="./data/inbox", api_key=None):
    """Workflow nocturne pour traitement automatis√©"""
```

#### `maintenance.py` - Maintenance Automatis√©e
**R√¥le** : Workflows de maintenance et optimisation
```python
@flow(name="database_maintenance")
async def database_maintenance_flow(vacuum_database=True, backup_database=True):
    """Workflow de maintenance de la base de donn√©es ChromaDB"""
    
@flow(name="cleanup_old_files", task_runner=ConcurrentTaskRunner())
async def cleanup_old_files_flow(max_age_days=7, dry_run=False):
    """Workflow de nettoyage des anciens fichiers"""
    
@flow(name="weekly_maintenance", task_runner=ConcurrentTaskRunner())
async def weekly_maintenance_flow(notification_email=None):
    """Workflow de maintenance hebdomadaire compl√®te"""
```

#### `monitoring.py` - Surveillance Syst√®me
**R√¥le** : Workflows de monitoring et alertes
```python
@flow(name="health_check_flow")
async def health_check_flow(alert_threshold=70, notification_email=None):
    """Workflow de surveillance de sant√© syst√®me"""
    
@flow(name="performance_monitoring_flow", task_runner=ConcurrentTaskRunner())
async def performance_monitoring_flow(generate_detailed_report=True):
    """Workflow de surveillance des performances"""
    
@flow(name="continuous_monitoring")
async def continuous_monitoring_flow(monitoring_duration_minutes=60):
    """Workflow de surveillance continue"""
```

#### `testing.py` - Tests Automatis√©s
**R√¥le** : Workflows de validation et tests
```python
@flow(name="automated_testing_flow", task_runner=ConcurrentTaskRunner())
async def automated_testing_flow(api_key, test_documents_folder="./tests/documents"):
    """Workflow de tests automatis√©s complets"""
    
@flow(name="regression_testing")
async def regression_testing_flow(api_key, baseline_report_path=None):
    """Workflow de tests de r√©gression"""
    
@flow(name="smoke_testing")
async def smoke_testing_flow(api_key):
    """Workflow de tests smoke (tests rapides de base)"""
```

#### `deployment.py` - Configuration D√©ploiement
**R√¥le** : Configuration des d√©ploiements Prefect
```python
# D√©ploiements avec planification automatique
nightly_processing_deployment = Deployment.build_from_flow(
    flow=nightly_batch_processing,
    name="nightly-document-processing",
    schedule=CronSchedule(cron="0 2 * * *"),  # 2h du matin
    parameters={"watch_folder": "./data/inbox"}
)

weekly_maintenance_deployment = Deployment.build_from_flow(
    flow=weekly_maintenance_flow,
    name="weekly-maintenance", 
    schedule=CronSchedule(cron="0 3 * * 0"),  # Dimanche 3h
)
```

### üìù **Dossier `scripts/` - Scripts d'Automatisation**

#### `setup_orchestration.py` - Configuration Automatique
**R√¥le** : Installation et configuration compl√®te automatis√©e
```python
def check_prefect_installation():
    """V√©rifier si Prefect est install√©"""
    
def install_prefect():
    """Installer Prefect et ses d√©pendances"""
    
def create_directories():
    """Cr√©er les r√©pertoires n√©cessaires"""
    
def create_test_documents():
    """Cr√©er des documents de test pour les workflows"""
    
def setup_prefect_config():
    """Configurer Prefect"""
    
def test_workflows_import():
    """Tester l'import des workflows"""
```

#### `start_prefect.sh` - D√©marrage Prefect
**R√¥le** : Script bash pour d√©marrage automatique
```bash
#!/bin/bash
# V√©rification pr√©requis
# Cr√©ation r√©pertoires
# Configuration base de donn√©es
# D√©marrage serveur + workers
# D√©ploiement workflows
# Validation sant√©
```

#### `stop_prefect.sh` - Arr√™t Prefect
**R√¥le** : Script bash pour arr√™t propre
```bash
#!/bin/bash
# Arr√™t workers
# Arr√™t serveur
# Nettoyage processus
# Lib√©ration ports
```

### üìä **Dossier `data/` - Stockage et Donn√©es**

#### Structure de Stockage
```
data/
‚îú‚îÄ‚îÄ uploads/              # Fichiers temporaires upload√©s
‚îú‚îÄ‚îÄ vectorstore/          # Base ChromaDB persistante
‚îÇ   ‚îú‚îÄ‚îÄ chroma.sqlite3    # Base SQLite ChromaDB
‚îÇ   ‚îî‚îÄ‚îÄ collections/      # Collections vectorielles
‚îú‚îÄ‚îÄ inbox/                # Documents pour traitement automatique
‚îú‚îÄ‚îÄ exports/              # Exports de sessions
‚îú‚îÄ‚îÄ backups/              # Sauvegardes automatiques
‚îÇ   ‚îú‚îÄ‚îÄ chromadb/         # Backups base vectorielle
‚îÇ   ‚îî‚îÄ‚îÄ configs/          # Backups configuration
‚îú‚îÄ‚îÄ reports/              # Rapports de performance
‚îú‚îÄ‚îÄ monitoring/           # Historique surveillance
‚îú‚îÄ‚îÄ workflow_results/     # R√©sultats workflows Prefect
‚îî‚îÄ‚îÄ prefect_storage/      # Artefacts Prefect
```

## üîß Flux de Donn√©es D√©taill√©s

### 1. **Traitement de Document**
```
User Upload ‚Üí FileValidator ‚Üí FileProcessor ‚Üí TextSplitter ‚Üí 
EnhancedVectorStore ‚Üí ChromaDB ‚Üí Success Feedback
```

### 2. **Conversation Intelligente**
```
User Question ‚Üí InputValidator ‚Üí VectorStore Search ‚Üí 
Context Retrieval ‚Üí PromptTemplate ‚Üí Mistral API ‚Üí 
Response + Sources ‚Üí ConversationMemory ‚Üí UI Display
```

### 3. **Orchestration Workflow**
```
User Action ‚Üí OrchestrationInterface ‚Üí PrefectBridge ‚Üí 
Workflow Execution ‚Üí Status Monitoring ‚Üí Results Display
```

### 4. **Monitoring Continu**
```
System Metrics ‚Üí PerformanceMonitor ‚Üí Health Calculation ‚Üí 
Alert Evaluation ‚Üí Notification Trigger ‚Üí Dashboard Update
```

## üéõÔ∏è Points d'Extension

### Ajouter un Nouveau Format de Document
1. **√âtendre FileProcessor**
```python
@staticmethod
def extract_text_from_pptx(file_path):
    """Extraction PowerPoint avec python-pptx"""
    # Impl√©mentation extraction
```

2. **Mettre √† jour Config**
```python
ALLOWED_EXTENSIONS = ['.pdf', '.docx', '.txt', '.pptx']
```

3. **Ajouter Pattern TextSplitter**
```python
'presentation': r'\nSlide \d+|\n(?:Titre|Title):'
```

### Ajouter un Nouveau Template
1. **D√©finir dans PromptTemplateManager**
```python
'custom_domain': """
Tu es un expert en [DOMAINE].
Contexte: {context}
Question: {question}
R√©ponds avec l'expertise sp√©cialis√©e...
"""
```

2. **Impl√©menter D√©tection Automatique**
```python
def detect_custom_domain(self, text):
    domain_keywords = ['keyword1', 'keyword2']
    # Logique de d√©tection
```

### Ajouter un Nouveau Workflow
1. **Cr√©er le Flow**
```python
@flow(name="custom_workflow")
async def custom_workflow_flow(param1, param2):
    """Workflow personnalis√©"""
    # Logique m√©tier
    return results
```

2. **Ajouter au PrefectBridge**
```python
async def trigger_custom_workflow(self, param1, param2):
    return await self.trigger_workflow("custom-workflow", {
        "param1": param1, "param2": param2
    })
```

3. **Int√©grer √† l'Interface**
```python
# Dans OrchestrationInterface
custom_btn = gr.Button("üîß Custom Workflow")
custom_btn.click(
    fn=prefect_bridge.custom_workflow_sync,
    inputs=[param1_input, param2_input],
    outputs=[result_output]
)
```

## üîç Debugging et D√©veloppement

### Variables d'Environnement de Debug
```bash
export DEBUG_MODE="true"
export LOG_LEVEL="DEBUG"
export DISABLE_EMBEDDINGS="true"  # Pour tests sans TensorFlow
export MOCK_MISTRAL_API="true"    # Pour tests sans API
```

### Points de Debug Importants
1. **Performance Monitor** : Toutes les op√©rations sont trac√©es
2. **Logging Centralis√©** : `logs/` avec rotation automatique
3. **Health Checks** : Surveillance continue des composants
4. **Exception Handling** : Gestion gracieuse des erreurs

### Tests de Composants
```python
# Test d'un composant isol√©
from app.components.text_splitter import SmartTextSplitter
splitter = SmartTextSplitter()
result = splitter.split_text_smart(text, 1000, 200, "academic")

# Test d'un workflow
from workflows.tasks import check_system_health
health = check_system_health()
```

## üöÄ D√©ploiement en Production

### Configuration Production
```python
# app/config.py
class ProductionConfig(Config):
    DEBUG = False
    LOG_LEVEL = "INFO"
    MAX_WORKERS = 6
    EMBEDDING_MODEL = "all-mpnet-base-v2"  # Plus performant
    CHROMADB_PATH = "/var/lib/dontreadme/vectorstore"
```

### Variables d'Environnement Production
```bash
export FLASK_ENV="production"
export PREFECT_API_URL="https://your-prefect-server.com/api"
export NOTIFICATION_EMAIL="admin@yourcompany.com"
export ALERT_THRESHOLD="80"
export BACKUP_RETENTION_DAYS="30"
```

### Monitoring Production
- **Logs** : Centralis√©s avec ELK Stack
- **M√©triques** : Prometheus + Grafana
- **Alertes** : PagerDuty/Slack integration
- **Health Checks** : Kubernetes liveness/readiness probes

## üìã Checklist D√©veloppement

### Avant Modification
- [ ] Lire cette documentation compl√®tement
- [ ] Comprendre l'architecture modulaire
- [ ] Identifier les points d'impact
- [ ] Cr√©er une branche de d√©veloppement

### Pendant D√©veloppement
- [ ] Suivre les patterns existants
- [ ] Ajouter tests unitaires appropri√©s
- [ ] Documenter les nouvelles fonctions
- [ ] Utiliser le PerformanceMonitor
- [ ] G√©rer les erreurs gracieusement

### Apr√®s Modification
- [ ] Tester en isolation
- [ ] Tester l'int√©gration compl√®te
- [ ] V√©rifier les performances
- [ ] Mettre √† jour la documentation
- [ ] Cr√©er une Pull Request

---

## üéØ Conclusion Technique

DontREADME est con√ßu avec une **architecture modulaire et extensible** qui permet :

‚úÖ **Facilit√© de maintenance** : Composants isol√©s et responsabilit√©s claires
‚úÖ **Extensibilit√©** : Points d'extension bien d√©finis
‚úÖ **Observabilit√©** : Monitoring et logging complets
‚úÖ **Robustesse** : Gestion d'erreurs et fallbacks
‚úÖ **Performance** : Optimisations et mise en cache

Le syst√®me est pr√™t pour la production et peut √©voluer selon vos besoins sp√©cifiques !

---

*Guide d√©veloppeur DontREADME - Version 1.0*  
*D√©velopp√© avec ‚ù§Ô∏è et Claude Sonnet 4*